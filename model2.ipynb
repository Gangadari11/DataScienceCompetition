{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444edb77-eafa-4078-8deb-71216a86af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "Train data shape: (206969, 26)\n",
      "Test data shape: (137971, 25)\n",
      "\n",
      "Preparing features...\n",
      "\n",
      "Number of features: 66\n",
      "\n",
      "Training Random Forest model...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.42      0.23      0.30     13708\n",
      "        good       0.46      0.86      0.60     18278\n",
      "     neutral       0.25      0.00      0.00      9408\n",
      "\n",
      "    accuracy                           0.46     41394\n",
      "   macro avg       0.38      0.36      0.30     41394\n",
      "weighted avg       0.40      0.46      0.36     41394\n",
      "\n",
      "\n",
      "Weighted F1 Score: 0.3640\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                                feature  importance\n",
      "8                  Date_Registered_year    0.296927\n",
      "4     Received_card_discount_percentage    0.113323\n",
      "6                         Product_value    0.074943\n",
      "0                                    id    0.064586\n",
      "5   Received_coupon_discount_percentage    0.052166\n",
      "1                                   age    0.051804\n",
      "25                    received_date_day    0.030197\n",
      "17                   released_date_year    0.026310\n",
      "20         estimated_delivery_date_year    0.023367\n",
      "14              purchased_datetime_year    0.023111\n",
      "\n",
      "Making predictions on test set...\n",
      "\n",
      "Submission Preview:\n",
      "   id customer_experience\n",
      "0   0                 bad\n",
      "1   1                 bad\n",
      "2   2                 bad\n",
      "3   3                 bad\n",
      "4   4                 bad\n",
      "\n",
      "Submission shape: (137971, 2)\n",
      "\n",
      "Value counts in predictions:\n",
      "customer_experience\n",
      "good       111818\n",
      "bad         26087\n",
      "neutral        66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Submission file created successfully!\n",
      "\n",
      "Verifying saved submission file:\n",
      "   id customer_experience\n",
      "0   0                 bad\n",
      "1   1                 bad\n",
      "2   2                 bad\n",
      "3   3                 bad\n",
      "4   4                 bad\n",
      "\n",
      "Shape of saved submission: (137971, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Prepare dataset by handling dates and categorical variables\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original data\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Fill missing values\n",
    "    data.fillna(0, inplace=True)\n",
    "    \n",
    "    # Convert date columns to datetime and extract features\n",
    "    date_cols = ['Date_Registered', 'payment_datetime', 'purchased_datetime', \n",
    "                 'released_date', 'estimated_delivery_date', 'received_date']\n",
    "    \n",
    "    for col in date_cols:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "            # Extract numerical features from dates\n",
    "            data[f'{col}_year'] = data[col].dt.year.fillna(-1).astype(int)\n",
    "            data[f'{col}_month'] = data[col].dt.month.fillna(-1).astype(int)\n",
    "            data[f'{col}_day'] = data[col].dt.day.fillna(-1).astype(int)\n",
    "            # Drop original date column\n",
    "            data = data.drop(columns=[col])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['Gender', 'Is_current_loyalty_program_member', 'loyalty_tier',\n",
    "                       'payment_method', 'purchase_medium', 'shipping_method',\n",
    "                       'product_category']\n",
    "    \n",
    "    # Only encode categorical columns that exist in the dataset\n",
    "    existing_cat_cols = [col for col in categorical_cols if col in data.columns]\n",
    "    data = pd.get_dummies(data, columns=existing_cat_cols, drop_first=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('train_dataset.csv')\n",
    "test_data = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "print(\"\\nTrain data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "\n",
    "# Prepare features\n",
    "print(\"\\nPreparing features...\")\n",
    "X_train_full = prepare_data(train_data)\n",
    "X_test = prepare_data(test_data)\n",
    "\n",
    "# Remove non-feature columns from training data\n",
    "cols_to_drop = ['customer_experience', 'user_id', 'transaction_id', \n",
    "                'order_id', 'tracking_number']\n",
    "feature_cols = [col for col in X_train_full.columns \n",
    "                if col not in cols_to_drop]\n",
    "\n",
    "X = X_train_full[feature_cols]\n",
    "y = train_data['customer_experience']\n",
    "\n",
    "print(\"\\nNumber of features:\", len(feature_cols))\n",
    "\n",
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Ensure test data has same columns as training data\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Initialize and train the model\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, \n",
    "                          target_names=le.classes_))\n",
    "\n",
    "# Calculate weighted F1 score\n",
    "weighted_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score: {weighted_f1:.4f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': model.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.sort_values('importance', \n",
    "                                   ascending=False).head(10))\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"\\nMaking predictions on test set...\")\n",
    "test_predictions = model.predict(X_test)\n",
    "test_predictions_labels = le.inverse_transform(test_predictions)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': range(len(test_predictions_labels)),\n",
    "    'customer_experience': test_predictions_labels\n",
    "})\n",
    "\n",
    "# Print submission information\n",
    "print(\"\\nSubmission Preview:\")\n",
    "print(submission.head())\n",
    "print(\"\\nSubmission shape:\", submission.shape)\n",
    "print(\"\\nValue counts in predictions:\")\n",
    "print(submission['customer_experience'].value_counts())\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission file created successfully!\")\n",
    "\n",
    "# Verify file contents\n",
    "print(\"\\nVerifying saved submission file:\")\n",
    "saved_submission = pd.read_csv('submission.csv')\n",
    "print(saved_submission.head())\n",
    "print(\"\\nShape of saved submission:\", saved_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb6845-300d-495a-b959-bdd3539bcedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83662e85-7afc-4b5c-af11-96131b955156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "Preparing features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numeric_features] = X_numeric_transformed\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_1552\\2334899676.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost model...\n",
      "\n",
      "Weighted F1 Score: 0.6957\n",
      "\n",
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Enhanced data preparation with optimized feature engineering\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Optimize memory usage\n",
    "    numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # More efficient filling of missing values\n",
    "    data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())\n",
    "    data[categorical_cols] = data[categorical_cols].fillna(data[categorical_cols].mode().iloc[0])\n",
    "    \n",
    "    # Optimized date processing\n",
    "    date_cols = ['Date_Registered', 'payment_datetime', 'purchased_datetime', \n",
    "                 'released_date', 'estimated_delivery_date', 'received_date']\n",
    "    \n",
    "    for col in date_cols:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "            data[f'{col}_year'] = data[col].dt.year.fillna(-1).astype('int16')\n",
    "            data[f'{col}_month'] = data[col].dt.month.fillna(-1).astype('int8')\n",
    "            data[f'{col}_day'] = data[col].dt.day.fillna(-1).astype('int8')\n",
    "            data[f'{col}_dayofweek'] = data[col].dt.dayofweek.fillna(-1).astype('int8')\n",
    "            data[f'{col}_quarter'] = data[col].dt.quarter.fillna(-1).astype('int8')\n",
    "            \n",
    "            # New temporal features\n",
    "            data[f'{col}_week'] = data[col].dt.isocalendar().week.fillna(-1).astype('int8')\n",
    "            data[f'{col}_day_part'] = pd.cut(data[col].dt.hour.fillna(-1), \n",
    "                                           bins=[-1, 6, 12, 18, 24], \n",
    "                                           labels=[0, 1, 2, 3]).astype('int8')\n",
    "    \n",
    "    # Enhanced time difference features\n",
    "    date_cols_dt = [col for col in date_cols if col in data.columns]\n",
    "    for i in range(len(date_cols_dt)):\n",
    "        for j in range(i + 1, len(date_cols_dt)):\n",
    "            col1, col2 = date_cols_dt[i], date_cols_dt[j]\n",
    "            diff_name = f'{col1.split(\"_\")[0]}_{col2.split(\"_\")[0]}_diff_days'\n",
    "            data[diff_name] = (data[col2] - data[col1]).dt.total_seconds() / (24*3600)\n",
    "            \n",
    "            # Add business days feature\n",
    "            data[f'{diff_name}_business'] = np.busday_count(\n",
    "                data[col1].dt.date.values.astype('datetime64[D]'),\n",
    "                data[col2].dt.date.values.astype('datetime64[D]')\n",
    "            )\n",
    "    \n",
    "    # Drop original date columns\n",
    "    data = data.drop(columns=[col for col in date_cols if col in data.columns])\n",
    "    \n",
    "    # Enhanced price features\n",
    "    if all(col in data.columns for col in ['Product_value', 'final_payment']):\n",
    "        data['discount_amount'] = data['Product_value'] - data['final_payment']\n",
    "        data['discount_percentage'] = (data['discount_amount'] / data['Product_value'] * 100).clip(0, 100)\n",
    "        data['price_tier'] = pd.qcut(data['Product_value'], q=5, labels=False, duplicates='drop')\n",
    "        \n",
    "        # New price features\n",
    "        data['price_per_loyalty_point'] = data['Product_value'] / (data['loyalty_points_redeemed'].clip(1))\n",
    "        data['relative_price'] = data['Product_value'] / data.groupby('product_category')['Product_value'].transform('mean')\n",
    "    \n",
    "    # Optimized categorical encoding\n",
    "    cat_cols = ['Gender', 'Is_current_loyalty_program_member', 'loyalty_tier',\n",
    "                'payment_method', 'purchase_medium', 'shipping_method',\n",
    "                'product_category']\n",
    "    \n",
    "    existing_cat_cols = [col for col in cat_cols if col in data.columns]\n",
    "    \n",
    "    # Target encoding with smoothing\n",
    "    le_dict = {}\n",
    "    for col in existing_cat_cols:\n",
    "        le_dict[col] = LabelEncoder()\n",
    "        data[col] = le_dict[col].fit_transform(data[col].astype(str))\n",
    "        \n",
    "    return data\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('train_dataset.csv')\n",
    "test_data = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "print(\"\\nPreparing features...\")\n",
    "X_train_full = prepare_data(train_data)\n",
    "X_test = prepare_data(test_data)\n",
    "\n",
    "# Feature selection\n",
    "cols_to_drop = ['customer_experience', 'user_id', 'transaction_id', \n",
    "                'order_id', 'tracking_number']\n",
    "feature_cols = [col for col in X_train_full.columns if col not in cols_to_drop]\n",
    "\n",
    "X = X_train_full[feature_cols]\n",
    "y = train_data['customer_experience']\n",
    "\n",
    "# Optimize numeric features\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "X_numeric = X[numeric_features]\n",
    "X_numeric_scaled = scaler.fit_transform(X_numeric)\n",
    "X_numeric_transformed = power.fit_transform(X_numeric_scaled)\n",
    "X[numeric_features] = X_numeric_transformed\n",
    "\n",
    "# Optimized PCA\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "pca_features = pca.fit_transform(X_numeric_transformed)\n",
    "for i in range(pca_features.shape[1]):\n",
    "    X[f'pca_feature_{i}'] = pca_features[:, i]\n",
    "\n",
    "# Target encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Optimized train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Prepare test data\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test_numeric = X_test[numeric_features]\n",
    "X_test_numeric_scaled = scaler.transform(X_test_numeric)\n",
    "X_test_numeric_transformed = power.transform(X_test_numeric_scaled)\n",
    "X_test[numeric_features] = X_test_numeric_transformed\n",
    "\n",
    "# Add PCA features to test data\n",
    "test_pca_features = pca.transform(X_test_numeric_transformed)\n",
    "for i in range(test_pca_features.shape[1]):\n",
    "    X_test[f'pca_feature_{i}'] = test_pca_features[:, i]\n",
    "\n",
    "# Optimized XGBoost parameters\n",
    "params = {\n",
    "    'n_estimators': 800,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.015,\n",
    "    'subsample': 0.85,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'min_child_weight': 2,\n",
    "    'gamma': 0.05,\n",
    "    'alpha': 0.05,\n",
    "    'lambda': 0.8,\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': 'hist',\n",
    "    'grow_policy': 'lossguide',\n",
    "    'max_leaves': 128,\n",
    "    'early_stopping_rounds':10\n",
    "}\n",
    "\n",
    "# Train model with early stopping\n",
    "print(\"\\nTraining XGBoost model...\")\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_val)\n",
    "weighted_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score: {weighted_f1:.4f}\")\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = model.predict(X_test)\n",
    "test_predictions_labels = le.inverse_transform(test_predictions)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': range(len(test_predictions_labels)),\n",
    "    'customer_experience': test_predictions_labels\n",
    "})\n",
    "submission.to_csv('submission13.csv', index=False)\n",
    "print(\"\\nSubmission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db852697-b959-43ba-97c4-2930e86ac3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0654a-c9a0-4a0e-8c86-20da09d7b0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e8309-940c-4232-8f79-fc05414f96bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77ff248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Preparing datasets...\n",
      "Training Random Forest model...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.43      0.23      0.30     13708\n",
      "        good       0.47      0.87      0.61     18278\n",
      "     neutral       0.39      0.00      0.00      9408\n",
      "\n",
      "    accuracy                           0.46     41394\n",
      "   macro avg       0.43      0.37      0.30     41394\n",
      "weighted avg       0.44      0.46      0.37     41394\n",
      "\n",
      "\n",
      "Weighted F1 Score: 0.3681\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                                feature  importance\n",
      "8                  Date_Registered_year    0.313026\n",
      "4     Received_card_discount_percentage    0.097646\n",
      "6                         Product_value    0.070578\n",
      "0                                    id    0.063803\n",
      "1                                   age    0.058418\n",
      "5   Received_coupon_discount_percentage    0.051652\n",
      "25                    received_date_day    0.030403\n",
      "20         estimated_delivery_date_year    0.022649\n",
      "11                payment_datetime_year    0.022551\n",
      "17                   released_date_year    0.021528\n",
      "\n",
      "Making predictions on test set...\n",
      "\n",
      "Submission Preview:\n",
      "   id customer_experience\n",
      "0   0                 bad\n",
      "1   1                 bad\n",
      "2   2                 bad\n",
      "3   3                 bad\n",
      "4   4                 bad\n",
      "\n",
      "Submission shape: (137971, 2)\n",
      "\n",
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "def prepare_data(df):\n",
    "    # Create a copy to avoid modifying original data\n",
    "    data = df.copy()\n",
    "\n",
    "    # Fill missing values\n",
    "    data.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert date columns to datetime and extract features\n",
    "    date_cols = ['Date_Registered', 'payment_datetime', 'purchased_datetime', \n",
    "                 'released_date', 'estimated_delivery_date', 'received_date']\n",
    "\n",
    "    for col in date_cols:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "            # Extract numerical features from dates\n",
    "            data[f'{col}_year'] = data[col].dt.year.fillna(-1).astype(int)\n",
    "            data[f'{col}_month'] = data[col].dt.month.fillna(-1).astype(int)\n",
    "            data[f'{col}_day'] = data[col].dt.day.fillna(-1).astype(int)\n",
    "            # Drop original date column\n",
    "            data = data.drop(columns=[col])\n",
    "\n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['Gender', 'product_category', 'payment_method', 'purchase_medium', 'shipping_method', 'loyalty_tier', 'Is_current_loyalty_program_member']\n",
    "\n",
    "    existing_cat_cols = [col for col in categorical_cols if col in data.columns]\n",
    "    data = pd.get_dummies(data, columns=existing_cat_cols, drop_first=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def train_and_predict(train_df, test_df):\n",
    "    # Preprocess training and test data\n",
    "    print(\"Preparing datasets...\")\n",
    "    X_train_full = prepare_data(train_df)\n",
    "    X_test = prepare_data(test_df)\n",
    "\n",
    "    # Remove non-feature columns from training data\n",
    "    cols_to_drop = ['customer_experience', 'user_id', 'transaction_id', \n",
    "                    'order_id', 'tracking_number']\n",
    "    feature_cols = [col for col in X_train_full.columns if col not in cols_to_drop]\n",
    "\n",
    "    X = X_train_full[feature_cols]\n",
    "    y = train_df['customer_experience']\n",
    "\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Ensure test data has same columns as training data\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    print(\"Training Random Forest model...\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred, target_names=le.classes_))\n",
    "\n",
    "    # Calculate weighted F1 score\n",
    "    weighted_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    print(f\"\\nWeighted F1 Score: {weighted_f1:.4f}\")\n",
    "\n",
    "    # Feature importance analysis\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    })\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.sort_values('importance', ascending=False).head(10))\n",
    "\n",
    "    # Make predictions on test set\n",
    "    print(\"\\nMaking predictions on test set...\")\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_predictions_labels = le.inverse_transform(test_predictions)\n",
    "\n",
    "    return test_predictions_labels\n",
    "\n",
    "# Example usage:\n",
    "print(\"Loading datasets...\")\n",
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "predictions = train_and_predict(train_df, test_df)\n",
    "\n",
    "# Save predictions\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'customer_experience': predictions\n",
    "})\n",
    "\n",
    "print(\"\\nSubmission Preview:\")\n",
    "print(submission.head())\n",
    "print(\"\\nSubmission shape:\", submission.shape)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c40572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dulak\n"
     ]
    }
   ],
   "source": [
    "%cd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e68df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

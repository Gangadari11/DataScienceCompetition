{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a88b6aa-7fb2-4419-bf37-d7ee50c64481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "Train data shape: (206969, 26)\n",
      "Test data shape: (137971, 25)\n",
      "\n",
      "Preparing features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['max_discount'] = data[discount_cols].max(axis=1)\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['min_discount'] = data[discount_cols].min(axis=1)\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['discount_range'] = data['max_discount'] - data['min_discount']\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['loyalty_tier_num'] = LabelEncoder().fit_transform(data['loyalty_tier'])\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['tier_price_interaction'] = data['loyalty_tier_num'] * data['Product_value']\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['min_discount'] = data[discount_cols].min(axis=1)\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['discount_range'] = data['max_discount'] - data['min_discount']\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['loyalty_tier_num'] = LabelEncoder().fit_transform(data['loyalty_tier'])\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['tier_price_interaction'] = data['loyalty_tier_num'] * data['Product_value']\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numeric_features] = X_numeric_transformed\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_3520\\1362342581.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'pca_feature_{i}'] = pca_features[:, i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of features: 110\n",
      "\n",
      "Training XGBoost model with cross-validation...\n",
      "Fold 1 F1 Score: 0.6950\n",
      "Fold 2 F1 Score: 0.6932\n",
      "Fold 3 F1 Score: 0.6939\n",
      "Fold 4 F1 Score: 0.6922\n",
      "Fold 5 F1 Score: 0.6960\n",
      "\n",
      "Mean CV F1 score: 0.6941 (+/- 0.0027)\n",
      "\n",
      "Training final model...\n",
      "[0]\tvalidation_0-mlogloss:1.09365\n",
      "[1]\tvalidation_0-mlogloss:1.08649\n",
      "[2]\tvalidation_0-mlogloss:1.07919\n",
      "[3]\tvalidation_0-mlogloss:1.07206\n",
      "[4]\tvalidation_0-mlogloss:1.06511\n",
      "[5]\tvalidation_0-mlogloss:1.05830\n",
      "[6]\tvalidation_0-mlogloss:1.05167\n",
      "[7]\tvalidation_0-mlogloss:1.04519\n",
      "[8]\tvalidation_0-mlogloss:1.03885\n",
      "[9]\tvalidation_0-mlogloss:1.03269\n",
      "[10]\tvalidation_0-mlogloss:1.02665\n",
      "[11]\tvalidation_0-mlogloss:1.02098\n",
      "[12]\tvalidation_0-mlogloss:1.01519\n",
      "[13]\tvalidation_0-mlogloss:1.00953\n",
      "[14]\tvalidation_0-mlogloss:1.00423\n",
      "[15]\tvalidation_0-mlogloss:0.99896\n",
      "[16]\tvalidation_0-mlogloss:0.99407\n",
      "[17]\tvalidation_0-mlogloss:0.98889\n",
      "[18]\tvalidation_0-mlogloss:0.98382\n",
      "[19]\tvalidation_0-mlogloss:0.97887\n",
      "[20]\tvalidation_0-mlogloss:0.97404\n",
      "[21]\tvalidation_0-mlogloss:0.97044\n",
      "[22]\tvalidation_0-mlogloss:0.96575\n",
      "[23]\tvalidation_0-mlogloss:0.96229\n",
      "[24]\tvalidation_0-mlogloss:0.95777\n",
      "[25]\tvalidation_0-mlogloss:0.95334\n",
      "[26]\tvalidation_0-mlogloss:0.94902\n",
      "[27]\tvalidation_0-mlogloss:0.94479\n",
      "[28]\tvalidation_0-mlogloss:0.94171\n",
      "[29]\tvalidation_0-mlogloss:0.93764\n",
      "[30]\tvalidation_0-mlogloss:0.93362\n",
      "[31]\tvalidation_0-mlogloss:0.93003\n",
      "[32]\tvalidation_0-mlogloss:0.92619\n",
      "[33]\tvalidation_0-mlogloss:0.92244\n",
      "[34]\tvalidation_0-mlogloss:0.91970\n",
      "[35]\tvalidation_0-mlogloss:0.91635\n",
      "[36]\tvalidation_0-mlogloss:0.91280\n",
      "[37]\tvalidation_0-mlogloss:0.90931\n",
      "[38]\tvalidation_0-mlogloss:0.90592\n",
      "[39]\tvalidation_0-mlogloss:0.90257\n",
      "[40]\tvalidation_0-mlogloss:0.89942\n",
      "[41]\tvalidation_0-mlogloss:0.89619\n",
      "[42]\tvalidation_0-mlogloss:0.89330\n",
      "[43]\tvalidation_0-mlogloss:0.89024\n",
      "[44]\tvalidation_0-mlogloss:0.88722\n",
      "[45]\tvalidation_0-mlogloss:0.88503\n",
      "[46]\tvalidation_0-mlogloss:0.88222\n",
      "[47]\tvalidation_0-mlogloss:0.88034\n",
      "[48]\tvalidation_0-mlogloss:0.87748\n",
      "[49]\tvalidation_0-mlogloss:0.87491\n",
      "[50]\tvalidation_0-mlogloss:0.87249\n",
      "[51]\tvalidation_0-mlogloss:0.87054\n",
      "[52]\tvalidation_0-mlogloss:0.86801\n",
      "[53]\tvalidation_0-mlogloss:0.86643\n",
      "[54]\tvalidation_0-mlogloss:0.86398\n",
      "[55]\tvalidation_0-mlogloss:0.86145\n",
      "[56]\tvalidation_0-mlogloss:0.85898\n",
      "[57]\tvalidation_0-mlogloss:0.85677\n",
      "[58]\tvalidation_0-mlogloss:0.85440\n",
      "[59]\tvalidation_0-mlogloss:0.85210\n",
      "[60]\tvalidation_0-mlogloss:0.84988\n",
      "[61]\tvalidation_0-mlogloss:0.84763\n",
      "[62]\tvalidation_0-mlogloss:0.84628\n",
      "[63]\tvalidation_0-mlogloss:0.84419\n",
      "[64]\tvalidation_0-mlogloss:0.84273\n",
      "[65]\tvalidation_0-mlogloss:0.84060\n",
      "[66]\tvalidation_0-mlogloss:0.83862\n",
      "[67]\tvalidation_0-mlogloss:0.83660\n",
      "[68]\tvalidation_0-mlogloss:0.83463\n",
      "[69]\tvalidation_0-mlogloss:0.83266\n",
      "[70]\tvalidation_0-mlogloss:0.83081\n",
      "[71]\tvalidation_0-mlogloss:0.82947\n",
      "[72]\tvalidation_0-mlogloss:0.82762\n",
      "[73]\tvalidation_0-mlogloss:0.82584\n",
      "[74]\tvalidation_0-mlogloss:0.82407\n",
      "[75]\tvalidation_0-mlogloss:0.82234\n",
      "[76]\tvalidation_0-mlogloss:0.82063\n",
      "[77]\tvalidation_0-mlogloss:0.81896\n",
      "[78]\tvalidation_0-mlogloss:0.81734\n",
      "[79]\tvalidation_0-mlogloss:0.81574\n",
      "[80]\tvalidation_0-mlogloss:0.81463\n",
      "[81]\tvalidation_0-mlogloss:0.81315\n",
      "[82]\tvalidation_0-mlogloss:0.81164\n",
      "[83]\tvalidation_0-mlogloss:0.81010\n",
      "[84]\tvalidation_0-mlogloss:0.80859\n",
      "[85]\tvalidation_0-mlogloss:0.80768\n",
      "[86]\tvalidation_0-mlogloss:0.80629\n",
      "[87]\tvalidation_0-mlogloss:0.80486\n",
      "[88]\tvalidation_0-mlogloss:0.80358\n",
      "[89]\tvalidation_0-mlogloss:0.80220\n",
      "[90]\tvalidation_0-mlogloss:0.80085\n",
      "[91]\tvalidation_0-mlogloss:0.79957\n",
      "[92]\tvalidation_0-mlogloss:0.79825\n",
      "[93]\tvalidation_0-mlogloss:0.79696\n",
      "[94]\tvalidation_0-mlogloss:0.79569\n",
      "[95]\tvalidation_0-mlogloss:0.79450\n",
      "[96]\tvalidation_0-mlogloss:0.79334\n",
      "[97]\tvalidation_0-mlogloss:0.79221\n",
      "[98]\tvalidation_0-mlogloss:0.79141\n",
      "[99]\tvalidation_0-mlogloss:0.79021\n",
      "[100]\tvalidation_0-mlogloss:0.78911\n",
      "[101]\tvalidation_0-mlogloss:0.78796\n",
      "[102]\tvalidation_0-mlogloss:0.78683\n",
      "[103]\tvalidation_0-mlogloss:0.78622\n",
      "[104]\tvalidation_0-mlogloss:0.78512\n",
      "[105]\tvalidation_0-mlogloss:0.78408\n",
      "[106]\tvalidation_0-mlogloss:0.78343\n",
      "[107]\tvalidation_0-mlogloss:0.78240\n",
      "[108]\tvalidation_0-mlogloss:0.78141\n",
      "[109]\tvalidation_0-mlogloss:0.78044\n",
      "[110]\tvalidation_0-mlogloss:0.77946\n",
      "[111]\tvalidation_0-mlogloss:0.77856\n",
      "[112]\tvalidation_0-mlogloss:0.77760\n",
      "[113]\tvalidation_0-mlogloss:0.77676\n",
      "[114]\tvalidation_0-mlogloss:0.77587\n",
      "[115]\tvalidation_0-mlogloss:0.77496\n",
      "[116]\tvalidation_0-mlogloss:0.77415\n",
      "[117]\tvalidation_0-mlogloss:0.77360\n",
      "[118]\tvalidation_0-mlogloss:0.77276\n",
      "[119]\tvalidation_0-mlogloss:0.77199\n",
      "[120]\tvalidation_0-mlogloss:0.77127\n",
      "[121]\tvalidation_0-mlogloss:0.77046\n",
      "[122]\tvalidation_0-mlogloss:0.76965\n",
      "[123]\tvalidation_0-mlogloss:0.76890\n",
      "[124]\tvalidation_0-mlogloss:0.76809\n",
      "[125]\tvalidation_0-mlogloss:0.76731\n",
      "[126]\tvalidation_0-mlogloss:0.76656\n",
      "[127]\tvalidation_0-mlogloss:0.76585\n",
      "[128]\tvalidation_0-mlogloss:0.76543\n",
      "[129]\tvalidation_0-mlogloss:0.76466\n",
      "[130]\tvalidation_0-mlogloss:0.76397\n",
      "[131]\tvalidation_0-mlogloss:0.76332\n",
      "[132]\tvalidation_0-mlogloss:0.76262\n",
      "[133]\tvalidation_0-mlogloss:0.76205\n",
      "[134]\tvalidation_0-mlogloss:0.76136\n",
      "[135]\tvalidation_0-mlogloss:0.76072\n",
      "[136]\tvalidation_0-mlogloss:0.76011\n",
      "[137]\tvalidation_0-mlogloss:0.75951\n",
      "[138]\tvalidation_0-mlogloss:0.75889\n",
      "[139]\tvalidation_0-mlogloss:0.75856\n",
      "[140]\tvalidation_0-mlogloss:0.75796\n",
      "[141]\tvalidation_0-mlogloss:0.75738\n",
      "[142]\tvalidation_0-mlogloss:0.75682\n",
      "[143]\tvalidation_0-mlogloss:0.75625\n",
      "[144]\tvalidation_0-mlogloss:0.75568\n",
      "[145]\tvalidation_0-mlogloss:0.75513\n",
      "[146]\tvalidation_0-mlogloss:0.75459\n",
      "[147]\tvalidation_0-mlogloss:0.75430\n",
      "[148]\tvalidation_0-mlogloss:0.75378\n",
      "[149]\tvalidation_0-mlogloss:0.75324\n",
      "[150]\tvalidation_0-mlogloss:0.75274\n",
      "[151]\tvalidation_0-mlogloss:0.75240\n",
      "[152]\tvalidation_0-mlogloss:0.75188\n",
      "[153]\tvalidation_0-mlogloss:0.75140\n",
      "[154]\tvalidation_0-mlogloss:0.75093\n",
      "[155]\tvalidation_0-mlogloss:0.75056\n",
      "[156]\tvalidation_0-mlogloss:0.75009\n",
      "[157]\tvalidation_0-mlogloss:0.74965\n",
      "[158]\tvalidation_0-mlogloss:0.74921\n",
      "[159]\tvalidation_0-mlogloss:0.74894\n",
      "[160]\tvalidation_0-mlogloss:0.74872\n",
      "[161]\tvalidation_0-mlogloss:0.74828\n",
      "[162]\tvalidation_0-mlogloss:0.74786\n",
      "[163]\tvalidation_0-mlogloss:0.74763\n",
      "[164]\tvalidation_0-mlogloss:0.74722\n",
      "[165]\tvalidation_0-mlogloss:0.74681\n",
      "[166]\tvalidation_0-mlogloss:0.74640\n",
      "[167]\tvalidation_0-mlogloss:0.74601\n",
      "[168]\tvalidation_0-mlogloss:0.74577\n",
      "[169]\tvalidation_0-mlogloss:0.74539\n",
      "[170]\tvalidation_0-mlogloss:0.74498\n",
      "[171]\tvalidation_0-mlogloss:0.74458\n",
      "[172]\tvalidation_0-mlogloss:0.74435\n",
      "[173]\tvalidation_0-mlogloss:0.74399\n",
      "[174]\tvalidation_0-mlogloss:0.74366\n",
      "[175]\tvalidation_0-mlogloss:0.74330\n",
      "[176]\tvalidation_0-mlogloss:0.74298\n",
      "[177]\tvalidation_0-mlogloss:0.74265\n",
      "[178]\tvalidation_0-mlogloss:0.74227\n",
      "[179]\tvalidation_0-mlogloss:0.74193\n",
      "[180]\tvalidation_0-mlogloss:0.74158\n",
      "[181]\tvalidation_0-mlogloss:0.74126\n",
      "[182]\tvalidation_0-mlogloss:0.74092\n",
      "[183]\tvalidation_0-mlogloss:0.74062\n",
      "[184]\tvalidation_0-mlogloss:0.74032\n",
      "[185]\tvalidation_0-mlogloss:0.74006\n",
      "[186]\tvalidation_0-mlogloss:0.73991\n",
      "[187]\tvalidation_0-mlogloss:0.73958\n",
      "[188]\tvalidation_0-mlogloss:0.73929\n",
      "[189]\tvalidation_0-mlogloss:0.73898\n",
      "[190]\tvalidation_0-mlogloss:0.73867\n",
      "[191]\tvalidation_0-mlogloss:0.73840\n",
      "[192]\tvalidation_0-mlogloss:0.73810\n",
      "[193]\tvalidation_0-mlogloss:0.73782\n",
      "[194]\tvalidation_0-mlogloss:0.73753\n",
      "[195]\tvalidation_0-mlogloss:0.73725\n",
      "[196]\tvalidation_0-mlogloss:0.73696\n",
      "[197]\tvalidation_0-mlogloss:0.73669\n",
      "[198]\tvalidation_0-mlogloss:0.73649\n",
      "[199]\tvalidation_0-mlogloss:0.73622\n",
      "[200]\tvalidation_0-mlogloss:0.73596\n",
      "[201]\tvalidation_0-mlogloss:0.73567\n",
      "[202]\tvalidation_0-mlogloss:0.73543\n",
      "[203]\tvalidation_0-mlogloss:0.73516\n",
      "[204]\tvalidation_0-mlogloss:0.73492\n",
      "[205]\tvalidation_0-mlogloss:0.73466\n",
      "[206]\tvalidation_0-mlogloss:0.73444\n",
      "[207]\tvalidation_0-mlogloss:0.73417\n",
      "[208]\tvalidation_0-mlogloss:0.73394\n",
      "[209]\tvalidation_0-mlogloss:0.73371\n",
      "[210]\tvalidation_0-mlogloss:0.73348\n",
      "[211]\tvalidation_0-mlogloss:0.73333\n",
      "[212]\tvalidation_0-mlogloss:0.73314\n",
      "[213]\tvalidation_0-mlogloss:0.73303\n",
      "[214]\tvalidation_0-mlogloss:0.73278\n",
      "[215]\tvalidation_0-mlogloss:0.73257\n",
      "[216]\tvalidation_0-mlogloss:0.73235\n",
      "[217]\tvalidation_0-mlogloss:0.73212\n",
      "[218]\tvalidation_0-mlogloss:0.73192\n",
      "[219]\tvalidation_0-mlogloss:0.73181\n",
      "[220]\tvalidation_0-mlogloss:0.73165\n",
      "[221]\tvalidation_0-mlogloss:0.73144\n",
      "[222]\tvalidation_0-mlogloss:0.73122\n",
      "[223]\tvalidation_0-mlogloss:0.73098\n",
      "[224]\tvalidation_0-mlogloss:0.73076\n",
      "[225]\tvalidation_0-mlogloss:0.73067\n",
      "[226]\tvalidation_0-mlogloss:0.73051\n",
      "[227]\tvalidation_0-mlogloss:0.73031\n",
      "[228]\tvalidation_0-mlogloss:0.73013\n",
      "[229]\tvalidation_0-mlogloss:0.72995\n",
      "[230]\tvalidation_0-mlogloss:0.72975\n",
      "[231]\tvalidation_0-mlogloss:0.72956\n",
      "[232]\tvalidation_0-mlogloss:0.72947\n",
      "[233]\tvalidation_0-mlogloss:0.72939\n",
      "[234]\tvalidation_0-mlogloss:0.72922\n",
      "[235]\tvalidation_0-mlogloss:0.72905\n",
      "[236]\tvalidation_0-mlogloss:0.72886\n",
      "[237]\tvalidation_0-mlogloss:0.72866\n",
      "[238]\tvalidation_0-mlogloss:0.72858\n",
      "[239]\tvalidation_0-mlogloss:0.72840\n",
      "[240]\tvalidation_0-mlogloss:0.72821\n",
      "[241]\tvalidation_0-mlogloss:0.72814\n",
      "[242]\tvalidation_0-mlogloss:0.72800\n",
      "[243]\tvalidation_0-mlogloss:0.72792\n",
      "[244]\tvalidation_0-mlogloss:0.72776\n",
      "[245]\tvalidation_0-mlogloss:0.72762\n",
      "[246]\tvalidation_0-mlogloss:0.72745\n",
      "[247]\tvalidation_0-mlogloss:0.72730\n",
      "[248]\tvalidation_0-mlogloss:0.72716\n",
      "[249]\tvalidation_0-mlogloss:0.72699\n",
      "[250]\tvalidation_0-mlogloss:0.72683\n",
      "[251]\tvalidation_0-mlogloss:0.72669\n",
      "[252]\tvalidation_0-mlogloss:0.72653\n",
      "[253]\tvalidation_0-mlogloss:0.72638\n",
      "[254]\tvalidation_0-mlogloss:0.72624\n",
      "[255]\tvalidation_0-mlogloss:0.72617\n",
      "[256]\tvalidation_0-mlogloss:0.72612\n",
      "[257]\tvalidation_0-mlogloss:0.72599\n",
      "[258]\tvalidation_0-mlogloss:0.72586\n",
      "[259]\tvalidation_0-mlogloss:0.72573\n",
      "[260]\tvalidation_0-mlogloss:0.72557\n",
      "[261]\tvalidation_0-mlogloss:0.72552\n",
      "[262]\tvalidation_0-mlogloss:0.72537\n",
      "[263]\tvalidation_0-mlogloss:0.72524\n",
      "[264]\tvalidation_0-mlogloss:0.72513\n",
      "[265]\tvalidation_0-mlogloss:0.72501\n",
      "[266]\tvalidation_0-mlogloss:0.72490\n",
      "[267]\tvalidation_0-mlogloss:0.72483\n",
      "[268]\tvalidation_0-mlogloss:0.72470\n",
      "[269]\tvalidation_0-mlogloss:0.72464\n",
      "[270]\tvalidation_0-mlogloss:0.72452\n",
      "[271]\tvalidation_0-mlogloss:0.72440\n",
      "[272]\tvalidation_0-mlogloss:0.72426\n",
      "[273]\tvalidation_0-mlogloss:0.72417\n",
      "[274]\tvalidation_0-mlogloss:0.72405\n",
      "[275]\tvalidation_0-mlogloss:0.72398\n",
      "[276]\tvalidation_0-mlogloss:0.72388\n",
      "[277]\tvalidation_0-mlogloss:0.72374\n",
      "[278]\tvalidation_0-mlogloss:0.72366\n",
      "[279]\tvalidation_0-mlogloss:0.72356\n",
      "[280]\tvalidation_0-mlogloss:0.72345\n",
      "[281]\tvalidation_0-mlogloss:0.72335\n",
      "[282]\tvalidation_0-mlogloss:0.72323\n",
      "[283]\tvalidation_0-mlogloss:0.72317\n",
      "[284]\tvalidation_0-mlogloss:0.72305\n",
      "[285]\tvalidation_0-mlogloss:0.72296\n",
      "[286]\tvalidation_0-mlogloss:0.72285\n",
      "[287]\tvalidation_0-mlogloss:0.72274\n",
      "[288]\tvalidation_0-mlogloss:0.72266\n",
      "[289]\tvalidation_0-mlogloss:0.72259\n",
      "[290]\tvalidation_0-mlogloss:0.72250\n",
      "[291]\tvalidation_0-mlogloss:0.72241\n",
      "[292]\tvalidation_0-mlogloss:0.72232\n",
      "[293]\tvalidation_0-mlogloss:0.72224\n",
      "[294]\tvalidation_0-mlogloss:0.72216\n",
      "[295]\tvalidation_0-mlogloss:0.72210\n",
      "[296]\tvalidation_0-mlogloss:0.72201\n",
      "[297]\tvalidation_0-mlogloss:0.72191\n",
      "[298]\tvalidation_0-mlogloss:0.72187\n",
      "[299]\tvalidation_0-mlogloss:0.72183\n",
      "[300]\tvalidation_0-mlogloss:0.72175\n",
      "[301]\tvalidation_0-mlogloss:0.72172\n",
      "[302]\tvalidation_0-mlogloss:0.72164\n",
      "[303]\tvalidation_0-mlogloss:0.72158\n",
      "[304]\tvalidation_0-mlogloss:0.72150\n",
      "[305]\tvalidation_0-mlogloss:0.72142\n",
      "[306]\tvalidation_0-mlogloss:0.72132\n",
      "[307]\tvalidation_0-mlogloss:0.72129\n",
      "[308]\tvalidation_0-mlogloss:0.72120\n",
      "[309]\tvalidation_0-mlogloss:0.72112\n",
      "[310]\tvalidation_0-mlogloss:0.72106\n",
      "[311]\tvalidation_0-mlogloss:0.72097\n",
      "[312]\tvalidation_0-mlogloss:0.72087\n",
      "[313]\tvalidation_0-mlogloss:0.72079\n",
      "[314]\tvalidation_0-mlogloss:0.72072\n",
      "[315]\tvalidation_0-mlogloss:0.72067\n",
      "[316]\tvalidation_0-mlogloss:0.72061\n",
      "[317]\tvalidation_0-mlogloss:0.72055\n",
      "[318]\tvalidation_0-mlogloss:0.72053\n",
      "[319]\tvalidation_0-mlogloss:0.72044\n",
      "[320]\tvalidation_0-mlogloss:0.72038\n",
      "[321]\tvalidation_0-mlogloss:0.72032\n",
      "[322]\tvalidation_0-mlogloss:0.72025\n",
      "[323]\tvalidation_0-mlogloss:0.72023\n",
      "[324]\tvalidation_0-mlogloss:0.72018\n",
      "[325]\tvalidation_0-mlogloss:0.72010\n",
      "[326]\tvalidation_0-mlogloss:0.72004\n",
      "[327]\tvalidation_0-mlogloss:0.71999\n",
      "[328]\tvalidation_0-mlogloss:0.71993\n",
      "[329]\tvalidation_0-mlogloss:0.71989\n",
      "[330]\tvalidation_0-mlogloss:0.71980\n",
      "[331]\tvalidation_0-mlogloss:0.71976\n",
      "[332]\tvalidation_0-mlogloss:0.71969\n",
      "[333]\tvalidation_0-mlogloss:0.71965\n",
      "[334]\tvalidation_0-mlogloss:0.71960\n",
      "[335]\tvalidation_0-mlogloss:0.71955\n",
      "[336]\tvalidation_0-mlogloss:0.71949\n",
      "[337]\tvalidation_0-mlogloss:0.71942\n",
      "[338]\tvalidation_0-mlogloss:0.71940\n",
      "[339]\tvalidation_0-mlogloss:0.71938\n",
      "[340]\tvalidation_0-mlogloss:0.71931\n",
      "[341]\tvalidation_0-mlogloss:0.71928\n",
      "[342]\tvalidation_0-mlogloss:0.71924\n",
      "[343]\tvalidation_0-mlogloss:0.71922\n",
      "[344]\tvalidation_0-mlogloss:0.71916\n",
      "[345]\tvalidation_0-mlogloss:0.71909\n",
      "[346]\tvalidation_0-mlogloss:0.71904\n",
      "[347]\tvalidation_0-mlogloss:0.71902\n",
      "[348]\tvalidation_0-mlogloss:0.71897\n",
      "[349]\tvalidation_0-mlogloss:0.71892\n",
      "[350]\tvalidation_0-mlogloss:0.71891\n",
      "[351]\tvalidation_0-mlogloss:0.71886\n",
      "[352]\tvalidation_0-mlogloss:0.71883\n",
      "[353]\tvalidation_0-mlogloss:0.71878\n",
      "[354]\tvalidation_0-mlogloss:0.71872\n",
      "[355]\tvalidation_0-mlogloss:0.71868\n",
      "[356]\tvalidation_0-mlogloss:0.71863\n",
      "[357]\tvalidation_0-mlogloss:0.71859\n",
      "[358]\tvalidation_0-mlogloss:0.71854\n",
      "[359]\tvalidation_0-mlogloss:0.71850\n",
      "[360]\tvalidation_0-mlogloss:0.71848\n",
      "[361]\tvalidation_0-mlogloss:0.71844\n",
      "[362]\tvalidation_0-mlogloss:0.71843\n",
      "[363]\tvalidation_0-mlogloss:0.71839\n",
      "[364]\tvalidation_0-mlogloss:0.71836\n",
      "[365]\tvalidation_0-mlogloss:0.71833\n",
      "[366]\tvalidation_0-mlogloss:0.71828\n",
      "[367]\tvalidation_0-mlogloss:0.71822\n",
      "[368]\tvalidation_0-mlogloss:0.71818\n",
      "[369]\tvalidation_0-mlogloss:0.71814\n",
      "[370]\tvalidation_0-mlogloss:0.71810\n",
      "[371]\tvalidation_0-mlogloss:0.71808\n",
      "[372]\tvalidation_0-mlogloss:0.71805\n",
      "[373]\tvalidation_0-mlogloss:0.71803\n",
      "[374]\tvalidation_0-mlogloss:0.71800\n",
      "[375]\tvalidation_0-mlogloss:0.71798\n",
      "[376]\tvalidation_0-mlogloss:0.71794\n",
      "[377]\tvalidation_0-mlogloss:0.71792\n",
      "[378]\tvalidation_0-mlogloss:0.71786\n",
      "[379]\tvalidation_0-mlogloss:0.71785\n",
      "[380]\tvalidation_0-mlogloss:0.71781\n",
      "[381]\tvalidation_0-mlogloss:0.71777\n",
      "[382]\tvalidation_0-mlogloss:0.71775\n",
      "[383]\tvalidation_0-mlogloss:0.71775\n",
      "[384]\tvalidation_0-mlogloss:0.71770\n",
      "[385]\tvalidation_0-mlogloss:0.71765\n",
      "[386]\tvalidation_0-mlogloss:0.71763\n",
      "[387]\tvalidation_0-mlogloss:0.71761\n",
      "[388]\tvalidation_0-mlogloss:0.71758\n",
      "[389]\tvalidation_0-mlogloss:0.71754\n",
      "[390]\tvalidation_0-mlogloss:0.71750\n",
      "[391]\tvalidation_0-mlogloss:0.71746\n",
      "[392]\tvalidation_0-mlogloss:0.71742\n",
      "[393]\tvalidation_0-mlogloss:0.71739\n",
      "[394]\tvalidation_0-mlogloss:0.71736\n",
      "[395]\tvalidation_0-mlogloss:0.71734\n",
      "[396]\tvalidation_0-mlogloss:0.71732\n",
      "[397]\tvalidation_0-mlogloss:0.71729\n",
      "[398]\tvalidation_0-mlogloss:0.71728\n",
      "[399]\tvalidation_0-mlogloss:0.71725\n",
      "[400]\tvalidation_0-mlogloss:0.71725\n",
      "[401]\tvalidation_0-mlogloss:0.71721\n",
      "[402]\tvalidation_0-mlogloss:0.71720\n",
      "[403]\tvalidation_0-mlogloss:0.71719\n",
      "[404]\tvalidation_0-mlogloss:0.71718\n",
      "[405]\tvalidation_0-mlogloss:0.71716\n",
      "[406]\tvalidation_0-mlogloss:0.71716\n",
      "[407]\tvalidation_0-mlogloss:0.71714\n",
      "[408]\tvalidation_0-mlogloss:0.71711\n",
      "[409]\tvalidation_0-mlogloss:0.71709\n",
      "[410]\tvalidation_0-mlogloss:0.71708\n",
      "[411]\tvalidation_0-mlogloss:0.71705\n",
      "[412]\tvalidation_0-mlogloss:0.71702\n",
      "[413]\tvalidation_0-mlogloss:0.71701\n",
      "[414]\tvalidation_0-mlogloss:0.71698\n",
      "[415]\tvalidation_0-mlogloss:0.71696\n",
      "[416]\tvalidation_0-mlogloss:0.71693\n",
      "[417]\tvalidation_0-mlogloss:0.71692\n",
      "[418]\tvalidation_0-mlogloss:0.71690\n",
      "[419]\tvalidation_0-mlogloss:0.71687\n",
      "[420]\tvalidation_0-mlogloss:0.71683\n",
      "[421]\tvalidation_0-mlogloss:0.71681\n",
      "[422]\tvalidation_0-mlogloss:0.71679\n",
      "[423]\tvalidation_0-mlogloss:0.71675\n",
      "[424]\tvalidation_0-mlogloss:0.71675\n",
      "[425]\tvalidation_0-mlogloss:0.71673\n",
      "[426]\tvalidation_0-mlogloss:0.71671\n",
      "[427]\tvalidation_0-mlogloss:0.71670\n",
      "[428]\tvalidation_0-mlogloss:0.71670\n",
      "[429]\tvalidation_0-mlogloss:0.71668\n",
      "[430]\tvalidation_0-mlogloss:0.71666\n",
      "[431]\tvalidation_0-mlogloss:0.71663\n",
      "[432]\tvalidation_0-mlogloss:0.71660\n",
      "[433]\tvalidation_0-mlogloss:0.71658\n",
      "[434]\tvalidation_0-mlogloss:0.71655\n",
      "[435]\tvalidation_0-mlogloss:0.71653\n",
      "[436]\tvalidation_0-mlogloss:0.71652\n",
      "[437]\tvalidation_0-mlogloss:0.71650\n",
      "[438]\tvalidation_0-mlogloss:0.71650\n",
      "[439]\tvalidation_0-mlogloss:0.71649\n",
      "[440]\tvalidation_0-mlogloss:0.71647\n",
      "[441]\tvalidation_0-mlogloss:0.71644\n",
      "[442]\tvalidation_0-mlogloss:0.71642\n",
      "[443]\tvalidation_0-mlogloss:0.71639\n",
      "[444]\tvalidation_0-mlogloss:0.71638\n",
      "[445]\tvalidation_0-mlogloss:0.71635\n",
      "[446]\tvalidation_0-mlogloss:0.71635\n",
      "[447]\tvalidation_0-mlogloss:0.71634\n",
      "[448]\tvalidation_0-mlogloss:0.71633\n",
      "[449]\tvalidation_0-mlogloss:0.71632\n",
      "[450]\tvalidation_0-mlogloss:0.71630\n",
      "[451]\tvalidation_0-mlogloss:0.71629\n",
      "[452]\tvalidation_0-mlogloss:0.71629\n",
      "[453]\tvalidation_0-mlogloss:0.71628\n",
      "[454]\tvalidation_0-mlogloss:0.71627\n",
      "[455]\tvalidation_0-mlogloss:0.71627\n",
      "[456]\tvalidation_0-mlogloss:0.71627\n",
      "[457]\tvalidation_0-mlogloss:0.71626\n",
      "[458]\tvalidation_0-mlogloss:0.71626\n",
      "[459]\tvalidation_0-mlogloss:0.71623\n",
      "[460]\tvalidation_0-mlogloss:0.71622\n",
      "[461]\tvalidation_0-mlogloss:0.71620\n",
      "[462]\tvalidation_0-mlogloss:0.71619\n",
      "[463]\tvalidation_0-mlogloss:0.71619\n",
      "[464]\tvalidation_0-mlogloss:0.71617\n",
      "[465]\tvalidation_0-mlogloss:0.71616\n",
      "[466]\tvalidation_0-mlogloss:0.71616\n",
      "[467]\tvalidation_0-mlogloss:0.71616\n",
      "[468]\tvalidation_0-mlogloss:0.71615\n",
      "[469]\tvalidation_0-mlogloss:0.71614\n",
      "[470]\tvalidation_0-mlogloss:0.71614\n",
      "[471]\tvalidation_0-mlogloss:0.71612\n",
      "[472]\tvalidation_0-mlogloss:0.71611\n",
      "[473]\tvalidation_0-mlogloss:0.71610\n",
      "[474]\tvalidation_0-mlogloss:0.71610\n",
      "[475]\tvalidation_0-mlogloss:0.71609\n",
      "[476]\tvalidation_0-mlogloss:0.71609\n",
      "[477]\tvalidation_0-mlogloss:0.71608\n",
      "[478]\tvalidation_0-mlogloss:0.71607\n",
      "[479]\tvalidation_0-mlogloss:0.71606\n",
      "[480]\tvalidation_0-mlogloss:0.71605\n",
      "[481]\tvalidation_0-mlogloss:0.71604\n",
      "[482]\tvalidation_0-mlogloss:0.71604\n",
      "[483]\tvalidation_0-mlogloss:0.71602\n",
      "[484]\tvalidation_0-mlogloss:0.71601\n",
      "[485]\tvalidation_0-mlogloss:0.71600\n",
      "[486]\tvalidation_0-mlogloss:0.71600\n",
      "[487]\tvalidation_0-mlogloss:0.71600\n",
      "[488]\tvalidation_0-mlogloss:0.71598\n",
      "[489]\tvalidation_0-mlogloss:0.71598\n",
      "[490]\tvalidation_0-mlogloss:0.71596\n",
      "[491]\tvalidation_0-mlogloss:0.71595\n",
      "[492]\tvalidation_0-mlogloss:0.71595\n",
      "[493]\tvalidation_0-mlogloss:0.71594\n",
      "[494]\tvalidation_0-mlogloss:0.71594\n",
      "[495]\tvalidation_0-mlogloss:0.71593\n",
      "[496]\tvalidation_0-mlogloss:0.71591\n",
      "[497]\tvalidation_0-mlogloss:0.71590\n",
      "[498]\tvalidation_0-mlogloss:0.71589\n",
      "[499]\tvalidation_0-mlogloss:0.71589\n",
      "[500]\tvalidation_0-mlogloss:0.71589\n",
      "[501]\tvalidation_0-mlogloss:0.71588\n",
      "[502]\tvalidation_0-mlogloss:0.71588\n",
      "[503]\tvalidation_0-mlogloss:0.71588\n",
      "[504]\tvalidation_0-mlogloss:0.71588\n",
      "[505]\tvalidation_0-mlogloss:0.71586\n",
      "[506]\tvalidation_0-mlogloss:0.71586\n",
      "[507]\tvalidation_0-mlogloss:0.71586\n",
      "[508]\tvalidation_0-mlogloss:0.71586\n",
      "[509]\tvalidation_0-mlogloss:0.71586\n",
      "[510]\tvalidation_0-mlogloss:0.71585\n",
      "[511]\tvalidation_0-mlogloss:0.71585\n",
      "[512]\tvalidation_0-mlogloss:0.71584\n",
      "[513]\tvalidation_0-mlogloss:0.71584\n",
      "[514]\tvalidation_0-mlogloss:0.71584\n",
      "[515]\tvalidation_0-mlogloss:0.71582\n",
      "[516]\tvalidation_0-mlogloss:0.71582\n",
      "[517]\tvalidation_0-mlogloss:0.71581\n",
      "[518]\tvalidation_0-mlogloss:0.71581\n",
      "[519]\tvalidation_0-mlogloss:0.71581\n",
      "[520]\tvalidation_0-mlogloss:0.71581\n",
      "[521]\tvalidation_0-mlogloss:0.71581\n",
      "[522]\tvalidation_0-mlogloss:0.71580\n",
      "[523]\tvalidation_0-mlogloss:0.71579\n",
      "[524]\tvalidation_0-mlogloss:0.71577\n",
      "[525]\tvalidation_0-mlogloss:0.71577\n",
      "[526]\tvalidation_0-mlogloss:0.71576\n",
      "[527]\tvalidation_0-mlogloss:0.71574\n",
      "[528]\tvalidation_0-mlogloss:0.71573\n",
      "[529]\tvalidation_0-mlogloss:0.71573\n",
      "[530]\tvalidation_0-mlogloss:0.71573\n",
      "[531]\tvalidation_0-mlogloss:0.71572\n",
      "[532]\tvalidation_0-mlogloss:0.71571\n",
      "[533]\tvalidation_0-mlogloss:0.71570\n",
      "[534]\tvalidation_0-mlogloss:0.71570\n",
      "[535]\tvalidation_0-mlogloss:0.71570\n",
      "[536]\tvalidation_0-mlogloss:0.71571\n",
      "[537]\tvalidation_0-mlogloss:0.71569\n",
      "[538]\tvalidation_0-mlogloss:0.71569\n",
      "[539]\tvalidation_0-mlogloss:0.71568\n",
      "[540]\tvalidation_0-mlogloss:0.71568\n",
      "[541]\tvalidation_0-mlogloss:0.71569\n",
      "[542]\tvalidation_0-mlogloss:0.71569\n",
      "[543]\tvalidation_0-mlogloss:0.71567\n",
      "[544]\tvalidation_0-mlogloss:0.71567\n",
      "[545]\tvalidation_0-mlogloss:0.71566\n",
      "[546]\tvalidation_0-mlogloss:0.71565\n",
      "[547]\tvalidation_0-mlogloss:0.71563\n",
      "[548]\tvalidation_0-mlogloss:0.71563\n",
      "[549]\tvalidation_0-mlogloss:0.71563\n",
      "[550]\tvalidation_0-mlogloss:0.71563\n",
      "[551]\tvalidation_0-mlogloss:0.71563\n",
      "[552]\tvalidation_0-mlogloss:0.71562\n",
      "[553]\tvalidation_0-mlogloss:0.71561\n",
      "[554]\tvalidation_0-mlogloss:0.71560\n",
      "[555]\tvalidation_0-mlogloss:0.71561\n",
      "[556]\tvalidation_0-mlogloss:0.71560\n",
      "[557]\tvalidation_0-mlogloss:0.71560\n",
      "[558]\tvalidation_0-mlogloss:0.71560\n",
      "[559]\tvalidation_0-mlogloss:0.71560\n",
      "[560]\tvalidation_0-mlogloss:0.71560\n",
      "[561]\tvalidation_0-mlogloss:0.71561\n",
      "[562]\tvalidation_0-mlogloss:0.71561\n",
      "[563]\tvalidation_0-mlogloss:0.71561\n",
      "[564]\tvalidation_0-mlogloss:0.71561\n",
      "[565]\tvalidation_0-mlogloss:0.71561\n",
      "[566]\tvalidation_0-mlogloss:0.71560\n",
      "[567]\tvalidation_0-mlogloss:0.71560\n",
      "[568]\tvalidation_0-mlogloss:0.71560\n",
      "[569]\tvalidation_0-mlogloss:0.71560\n",
      "[570]\tvalidation_0-mlogloss:0.71560\n",
      "[571]\tvalidation_0-mlogloss:0.71560\n",
      "[572]\tvalidation_0-mlogloss:0.71558\n",
      "[573]\tvalidation_0-mlogloss:0.71557\n",
      "[574]\tvalidation_0-mlogloss:0.71556\n",
      "[575]\tvalidation_0-mlogloss:0.71555\n",
      "[576]\tvalidation_0-mlogloss:0.71555\n",
      "[577]\tvalidation_0-mlogloss:0.71555\n",
      "[578]\tvalidation_0-mlogloss:0.71555\n",
      "[579]\tvalidation_0-mlogloss:0.71554\n",
      "[580]\tvalidation_0-mlogloss:0.71554\n",
      "[581]\tvalidation_0-mlogloss:0.71553\n",
      "[582]\tvalidation_0-mlogloss:0.71553\n",
      "[583]\tvalidation_0-mlogloss:0.71553\n",
      "[584]\tvalidation_0-mlogloss:0.71552\n",
      "[585]\tvalidation_0-mlogloss:0.71551\n",
      "[586]\tvalidation_0-mlogloss:0.71552\n",
      "[587]\tvalidation_0-mlogloss:0.71552\n",
      "[588]\tvalidation_0-mlogloss:0.71552\n",
      "[589]\tvalidation_0-mlogloss:0.71553\n",
      "[590]\tvalidation_0-mlogloss:0.71552\n",
      "[591]\tvalidation_0-mlogloss:0.71551\n",
      "[592]\tvalidation_0-mlogloss:0.71551\n",
      "[593]\tvalidation_0-mlogloss:0.71550\n",
      "[594]\tvalidation_0-mlogloss:0.71551\n",
      "[595]\tvalidation_0-mlogloss:0.71549\n",
      "[596]\tvalidation_0-mlogloss:0.71549\n",
      "[597]\tvalidation_0-mlogloss:0.71549\n",
      "[598]\tvalidation_0-mlogloss:0.71549\n",
      "[599]\tvalidation_0-mlogloss:0.71549\n",
      "[600]\tvalidation_0-mlogloss:0.71549\n",
      "[601]\tvalidation_0-mlogloss:0.71549\n",
      "[602]\tvalidation_0-mlogloss:0.71548\n",
      "[603]\tvalidation_0-mlogloss:0.71547\n",
      "[604]\tvalidation_0-mlogloss:0.71546\n",
      "[605]\tvalidation_0-mlogloss:0.71545\n",
      "[606]\tvalidation_0-mlogloss:0.71545\n",
      "[607]\tvalidation_0-mlogloss:0.71544\n",
      "[608]\tvalidation_0-mlogloss:0.71545\n",
      "[609]\tvalidation_0-mlogloss:0.71544\n",
      "[610]\tvalidation_0-mlogloss:0.71544\n",
      "[611]\tvalidation_0-mlogloss:0.71543\n",
      "[612]\tvalidation_0-mlogloss:0.71543\n",
      "[613]\tvalidation_0-mlogloss:0.71544\n",
      "[614]\tvalidation_0-mlogloss:0.71544\n",
      "[615]\tvalidation_0-mlogloss:0.71543\n",
      "[616]\tvalidation_0-mlogloss:0.71544\n",
      "[617]\tvalidation_0-mlogloss:0.71544\n",
      "[618]\tvalidation_0-mlogloss:0.71544\n",
      "[619]\tvalidation_0-mlogloss:0.71543\n",
      "[620]\tvalidation_0-mlogloss:0.71543\n",
      "[621]\tvalidation_0-mlogloss:0.71543\n",
      "[622]\tvalidation_0-mlogloss:0.71542\n",
      "[623]\tvalidation_0-mlogloss:0.71542\n",
      "[624]\tvalidation_0-mlogloss:0.71543\n",
      "[625]\tvalidation_0-mlogloss:0.71543\n",
      "[626]\tvalidation_0-mlogloss:0.71543\n",
      "[627]\tvalidation_0-mlogloss:0.71543\n",
      "[628]\tvalidation_0-mlogloss:0.71542\n",
      "[629]\tvalidation_0-mlogloss:0.71542\n",
      "[630]\tvalidation_0-mlogloss:0.71542\n",
      "[631]\tvalidation_0-mlogloss:0.71542\n",
      "[632]\tvalidation_0-mlogloss:0.71543\n",
      "[633]\tvalidation_0-mlogloss:0.71543\n",
      "[634]\tvalidation_0-mlogloss:0.71543\n",
      "[635]\tvalidation_0-mlogloss:0.71543\n",
      "[636]\tvalidation_0-mlogloss:0.71544\n",
      "[637]\tvalidation_0-mlogloss:0.71544\n",
      "[638]\tvalidation_0-mlogloss:0.71544\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.60      0.71      0.65     10281\n",
      "        good       0.73      0.68      0.70     13708\n",
      "     neutral       0.83      0.69      0.75      7057\n",
      "\n",
      "    accuracy                           0.69     31046\n",
      "   macro avg       0.72      0.70      0.70     31046\n",
      "weighted avg       0.71      0.69      0.70     31046\n",
      "\n",
      "\n",
      "Weighted F1 Score: 0.6973\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                         feature  importance\n",
      "65      received_date_is_weekend    0.205367\n",
      "63       received_date_dayofweek    0.112605\n",
      "71       Date_released_diff_days    0.079758\n",
      "80  purchased_received_diff_days    0.052271\n",
      "77    payment_received_diff_days    0.051539\n",
      "85               discount_amount    0.048223\n",
      "72      Date_estimated_diff_days    0.037447\n",
      "73       Date_received_diff_days    0.030440\n",
      "94                total_discount    0.019467\n",
      "97                discount_range    0.012547\n",
      "\n",
      "Making predictions on test set...\n",
      "\n",
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Enhanced data preparation with advanced feature engineering\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original data\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Fill missing values with appropriate strategies\n",
    "    numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Fill numeric columns with median\n",
    "    for col in numeric_cols:\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "    \n",
    "    # Fill categorical columns with mode\n",
    "    for col in categorical_cols:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "    \n",
    "    # Convert date columns to datetime and extract features\n",
    "    date_cols = ['Date_Registered', 'payment_datetime', 'purchased_datetime', \n",
    "                 'released_date', 'estimated_delivery_date', 'received_date']\n",
    "    \n",
    "    for col in date_cols:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "            # Extract numerical features from dates\n",
    "            data[f'{col}_year'] = data[col].dt.year.fillna(-1).astype(int)\n",
    "            data[f'{col}_month'] = data[col].dt.month.fillna(-1).astype(int)\n",
    "            data[f'{col}_day'] = data[col].dt.day.fillna(-1).astype(int)\n",
    "            data[f'{col}_dayofweek'] = data[col].dt.dayofweek.fillna(-1).astype(int)\n",
    "            data[f'{col}_quarter'] = data[col].dt.quarter.fillna(-1).astype(int)\n",
    "            data[f'{col}_is_weekend'] = (data[col].dt.dayofweek >= 5).astype(int)\n",
    "            data[f'{col}_is_month_end'] = (data[col].dt.is_month_end).astype(int)\n",
    "            data[f'{col}_is_month_start'] = (data[col].dt.is_month_start).astype(int)\n",
    "            data[f'{col}_hour'] = data[col].dt.hour.fillna(-1).astype(int)\n",
    "    \n",
    "    # Calculate time differences between all date pairs\n",
    "    date_cols_dt = [col for col in date_cols if col in data.columns]\n",
    "    for i in range(len(date_cols_dt)):\n",
    "        for j in range(i + 1, len(date_cols_dt)):\n",
    "            col1, col2 = date_cols_dt[i], date_cols_dt[j]\n",
    "            diff_name = f'{col1.split(\"_\")[0]}_{col2.split(\"_\")[0]}_diff_days'\n",
    "            data[diff_name] = (data[col2] - data[col1]).dt.total_seconds() / (24*3600)\n",
    "    \n",
    "    # Drop original date columns\n",
    "    for col in date_cols:\n",
    "        if col in data.columns:\n",
    "            data = data.drop(columns=[col])\n",
    "    \n",
    "    # Create price-related features\n",
    "    if 'Product_value' in data.columns and 'final_payment' in data.columns:\n",
    "        data['price_per_loyalty_point'] = data['Product_value'] / (data['loyalty_points_redeemed'].clip(1))\n",
    "\n",
    "        data['discount_amount'] = data['Product_value'] - data['final_payment']\n",
    "        data['discount_percentage'] = (data['discount_amount'] / data['Product_value'] * 100).clip(0, 100)\n",
    "        data['price_tier'] = pd.qcut(data['Product_value'], q=10, labels=False, duplicates='drop')\n",
    "        data['price_to_loyalty_ratio'] = data['Product_value'] / (data['loyalty_points_redeemed'] + 1)\n",
    "        \n",
    "        # Log transform price features\n",
    "        data['log_product_value'] = np.log1p(data['Product_value'])\n",
    "        data['log_final_payment'] = np.log1p(data['final_payment'])\n",
    "    \n",
    "    # Enhanced loyalty features\n",
    "    if 'loyalty_points_redeemed' in data.columns:\n",
    "        data['has_redeemed_points'] = (data['loyalty_points_redeemed'] > 0).astype(int)\n",
    "        data['log_loyalty_points'] = np.log1p(data['loyalty_points_redeemed'])\n",
    "        data['points_to_value_ratio'] = data['loyalty_points_redeemed'] / (data['Product_value'] + 1)\n",
    "    \n",
    "    # Aggregate discount features\n",
    "    discount_cols = [col for col in data.columns if 'discount_percentage' in col]\n",
    "    if discount_cols:\n",
    "        data['total_discount'] = data[discount_cols].sum(axis=1)\n",
    "        data['max_discount'] = data[discount_cols].max(axis=1)\n",
    "        data['min_discount'] = data[discount_cols].min(axis=1)\n",
    "        data['discount_range'] = data['max_discount'] - data['min_discount']\n",
    "    \n",
    "    # Interaction features\n",
    "    if 'loyalty_tier' in data.columns:\n",
    "        data['loyalty_tier'] = data['loyalty_tier'].astype(str)\n",
    "        data['loyalty_tier_num'] = LabelEncoder().fit_transform(data['loyalty_tier'])\n",
    "        data['tier_price_interaction'] = data['loyalty_tier_num'] * data['Product_value']\n",
    "    \n",
    "    # Encode categorical variables with target encoding\n",
    "    categorical_cols = ['Gender', 'Is_current_loyalty_program_member', 'loyalty_tier',\n",
    "                       'payment_method', 'purchase_medium', 'shipping_method',\n",
    "                       'product_category']\n",
    "    \n",
    "    # Only encode categorical columns that exist in the dataset\n",
    "    existing_cat_cols = [col for col in categorical_cols if col in data.columns]\n",
    "    \n",
    "    # Use LabelEncoder for categorical variables\n",
    "    le_dict = {}\n",
    "    for col in existing_cat_cols:\n",
    "        le_dict[col] = LabelEncoder()\n",
    "        data[col] = le_dict[col].fit_transform(data[col].astype(str))\n",
    "        \n",
    "    return data\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('train_dataset.csv')\n",
    "test_data = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "print(\"\\nTrain data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "\n",
    "# Prepare features\n",
    "print(\"\\nPreparing features...\")\n",
    "X_train_full = prepare_data(train_data)\n",
    "X_test = prepare_data(test_data)\n",
    "\n",
    "# Remove non-feature columns from training data\n",
    "cols_to_drop = ['customer_experience', 'user_id', 'transaction_id', \n",
    "                'order_id', 'tracking_number']\n",
    "feature_cols = [col for col in X_train_full.columns \n",
    "                if col not in cols_to_drop]\n",
    "\n",
    "X = X_train_full[feature_cols]\n",
    "y = train_data['customer_experience']\n",
    "\n",
    "# Scale numerical features and apply power transform\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "X_numeric = X[numeric_features]\n",
    "X_numeric_scaled = scaler.fit_transform(X_numeric)\n",
    "X_numeric_transformed = power.fit_transform(X_numeric_scaled)\n",
    "X[numeric_features] = X_numeric_transformed\n",
    "\n",
    "# Add PCA features\n",
    "pca = PCA(n_components=10)\n",
    "pca_features = pca.fit_transform(X_numeric_transformed)\n",
    "for i in range(pca_features.shape[1]):\n",
    "    X[f'pca_feature_{i}'] = pca_features[:, i]\n",
    "\n",
    "print(\"\\nNumber of features:\", len(X.columns))\n",
    "\n",
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.15,  # changed from 0.2\n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Prepare test data\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test_numeric = X_test[numeric_features]\n",
    "X_test_numeric_scaled = scaler.transform(X_test_numeric)\n",
    "X_test_numeric_transformed = power.transform(X_test_numeric_scaled)\n",
    "X_test[numeric_features] = X_test_numeric_transformed\n",
    "\n",
    "# Add PCA features to test data\n",
    "test_pca_features = pca.transform(X_test_numeric_transformed)\n",
    "for i in range(test_pca_features.shape[1]):\n",
    "    X_test[f'pca_feature_{i}'] = test_pca_features[:, i]\n",
    "\n",
    "# Optimized XGBoost parameters\n",
    "params = {\n",
    "    'n_estimators': 1000,  # keep same\n",
    "    'max_depth': 8,        # increased from 7\n",
    "    'learning_rate': 0.015,  # increased from 0.01\n",
    "    'subsample': 0.85,      # increased from 0.8\n",
    "    'colsample_bytree': 0.85,  # increased from 0.8\n",
    "    'min_child_weight': 2,    # decreased from 3\n",
    "    'gamma': 0.05,           # decreased from 0.1\n",
    "    'alpha': 0.05,           # decreased from 0.1\n",
    "    'lambda': 0.8,           # decreased from 1\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': 'hist',\n",
    "    'early_stopping_rounds': 15,  # increased from 10\n",
    "    'grow_policy': 'lossguide'    # added this\n",
    "}\n",
    "\n",
    "# Initialize and train model with StratifiedKFold\n",
    "print(\"\\nTraining XGBoost model with cross-validation...\")\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    fold_model = xgb.XGBClassifier(**params)\n",
    "    fold_model.fit(\n",
    "        X_fold_train, y_fold_train,\n",
    "        eval_set=[(X_fold_val, y_fold_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    fold_pred = fold_model.predict(X_fold_val)\n",
    "    fold_score = f1_score(y_fold_val, fold_pred, average='weighted')\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold} F1 Score: {fold_score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1 score: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores) * 2:.4f})\")\n",
    "\n",
    "# Train final model on full training data\n",
    "print(\"\\nTraining final model...\")\n",
    "final_model = xgb.XGBClassifier(**params)\n",
    "final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred = final_model.predict(X_val)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Calculate weighted F1 score\n",
    "weighted_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score: {weighted_f1:.4f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': final_model.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False).head(10))\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"\\nMaking predictions on test set...\")\n",
    "test_predictions = final_model.predict(X_test)\n",
    "test_predictions_labels = le.inverse_transform(test_predictions)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': range(len(test_predictions_labels)),\n",
    "    'customer_experience': test_predictions_labels\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('submission15.csv', index=False)\n",
    "print(\"\\nSubmission file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

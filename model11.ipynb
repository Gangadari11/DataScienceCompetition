{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c04c52-4d67-44dc-9ffa-5c215651966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "Preparing features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 159\u001b[0m\n\u001b[0;32m    156\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPreparing features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 159\u001b[0m X_train_full \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m X_test \u001b[38;5;241m=\u001b[39m prepare_data(test_data)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Remove non-feature columns\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# KNN imputation for numeric columns\u001b[39;00m\n\u001b[0;32m     26\u001b[0m imputer \u001b[38;5;241m=\u001b[39m KNNImputer(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m data[numeric_cols] \u001b[38;5;241m=\u001b[39m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumeric_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Fill categorical columns with mode\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\impute\\_knn.py:367\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# process in fixed-memory chunks\u001b[39;00m\n\u001b[0;32m    359\u001b[0m gen \u001b[38;5;241m=\u001b[39m pairwise_distances_chunked(\n\u001b[0;32m    360\u001b[0m     X[row_missing_idx, :],\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     reduce_func\u001b[38;5;241m=\u001b[39mprocess_chunk,\n\u001b[0;32m    366\u001b[0m )\n\u001b[1;32m--> 367\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# process_chunk modifies X in place. No return value.\u001b[39;49;00m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_empty_features:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:2172\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2171\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2172\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2174\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2175\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2176\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2178\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:2375\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2372\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2373\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:1893\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1890\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1896\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:522\u001b[0m, in \u001b[0;36mnan_euclidean_distances\u001b[1;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[0;32m    519\u001b[0m X[missing_X] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    520\u001b[0m Y[missing_Y] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 522\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# Adjust distances for missing values\u001b[39;00m\n\u001b[0;32m    525\u001b[0m XX \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m*\u001b[39m X\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:372\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    368\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m         )\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:407\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    404\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    409\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\extmath.py:208\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m--> 208\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m ):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\scipy\\sparse\\_base.py:1335\u001b[0m, in \u001b[0;36missparse\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A namespace class to separate sparray from spmatrix\"\"\"\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[1;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Enhanced data preparation with advanced feature engineering\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Advanced missing value imputation using KNN\n",
    "    numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # KNN imputation for numeric columns\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
    "    \n",
    "    # Fill categorical columns with mode\n",
    "    for col in categorical_cols:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "    \n",
    "    # Date processing (keeping original implementation plus new features)\n",
    "    date_cols = ['Date_Registered', 'payment_datetime', 'purchased_datetime', \n",
    "                 'released_date', 'estimated_delivery_date', 'received_date']\n",
    "    \n",
    "    for col in date_cols:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "            # Original date features\n",
    "            data[f'{col}_year'] = data[col].dt.year.fillna(-1).astype(int)\n",
    "            data[f'{col}_month'] = data[col].dt.month.fillna(-1).astype(int)\n",
    "            data[f'{col}_day'] = data[col].dt.day.fillna(-1).astype(int)\n",
    "            data[f'{col}_dayofweek'] = data[col].dt.dayofweek.fillna(-1).astype(int)\n",
    "            data[f'{col}_quarter'] = data[col].dt.quarter.fillna(-1).astype(int)\n",
    "            data[f'{col}_is_weekend'] = (data[col].dt.dayofweek >= 5).astype(int)\n",
    "            data[f'{col}_is_month_end'] = (data[col].dt.is_month_end).astype(int)\n",
    "            data[f'{col}_is_month_start'] = (data[col].dt.is_month_start).astype(int)\n",
    "            data[f'{col}_hour'] = data[col].dt.hour.fillna(-1).astype(int)\n",
    "            \n",
    "            # New date features\n",
    "            data[f'{col}_week'] = data[col].dt.isocalendar().week.fillna(-1).astype(int)\n",
    "            data[f'{col}_is_holiday'] = ((data[col].dt.month == 12) & \n",
    "                                       (data[col].dt.day >= 20)).astype(int)\n",
    "            data[f'{col}_season'] = pd.cut(data[col].dt.month, bins=[-np.inf, 3, 6, 9, np.inf], \n",
    "                                         labels=[0, 1, 2, 3]).astype(int)\n",
    "    \n",
    "    # Enhanced time difference features\n",
    "    date_cols_dt = [col for col in date_cols if col in data.columns]\n",
    "    for i in range(len(date_cols_dt)):\n",
    "        for j in range(i + 1, len(date_cols_dt)):\n",
    "            col1, col2 = date_cols_dt[i], date_cols_dt[j]\n",
    "            diff_seconds = (data[col2] - data[col1]).dt.total_seconds()\n",
    "            \n",
    "            # Days difference\n",
    "            data[f'{col1.split(\"_\")[0]}_{col2.split(\"_\")[0]}_diff_days'] = diff_seconds / (24*3600)\n",
    "            # Hours difference\n",
    "            data[f'{col1.split(\"_\")[0]}_{col2.split(\"_\")[0]}_diff_hours'] = diff_seconds / 3600\n",
    "            # Business days difference\n",
    "            data[f'{col1.split(\"_\")[0]}_{col2.split(\"_\")[0]}_business_days'] = np.busday_count(\n",
    "                data[col1].dt.date.values.astype('datetime64[D]'),\n",
    "                data[col2].dt.date.values.astype('datetime64[D]')\n",
    "            )\n",
    "    \n",
    "    # Drop original date columns\n",
    "    for col in date_cols:\n",
    "        if col in data.columns:\n",
    "            data = data.drop(columns=[col])\n",
    "    \n",
    "    # Enhanced price features\n",
    "    if 'Product_value' in data.columns and 'final_payment' in data.columns:\n",
    "        data['discount_amount'] = data['Product_value'] - data['final_payment']\n",
    "        data['discount_percentage'] = (data['discount_amount'] / data['Product_value'] * 100).clip(0, 100)\n",
    "        data['price_tier'] = pd.qcut(data['Product_value'], q=20, labels=False, duplicates='drop')  # Increased bins\n",
    "        data['price_to_loyalty_ratio'] = data['Product_value'] / (data['loyalty_points_redeemed'] + 1)\n",
    "        \n",
    "        # Advanced price transformations\n",
    "        data['log_product_value'] = np.log1p(data['Product_value'])\n",
    "        data['log_final_payment'] = np.log1p(data['final_payment'])\n",
    "        data['sqrt_product_value'] = np.sqrt(data['Product_value'])\n",
    "        data['cubic_product_value'] = np.cbrt(data['Product_value'])\n",
    "    \n",
    "    # Advanced categorical encoding\n",
    "    categorical_cols = ['Gender', 'Is_current_loyalty_program_member', 'loyalty_tier',\n",
    "                       'payment_method', 'purchase_medium', 'shipping_method',\n",
    "                       'product_category']\n",
    "    \n",
    "    existing_cat_cols = [col for col in categorical_cols if col in data.columns]\n",
    "    \n",
    "    # Target encoding with smoothing\n",
    "    le_dict = {}\n",
    "    for col in existing_cat_cols:\n",
    "        le_dict[col] = LabelEncoder()\n",
    "        data[col] = le_dict[col].fit_transform(data[col].astype(str))\n",
    "        \n",
    "        # Create interaction features between categorical variables\n",
    "        for col2 in existing_cat_cols:\n",
    "            if col != col2:\n",
    "                data[f'{col}_{col2}_interaction'] = data[col] * data[col2]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter optimization\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "    \n",
    "    cv_scores = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_fold_train, y_fold_train,\n",
    "                 eval_set=[(X_fold_val, y_fold_val)],\n",
    "                 early_stopping_rounds=50,\n",
    "                 verbose=False)\n",
    "        \n",
    "        fold_pred = model.predict(X_fold_val)\n",
    "        fold_score = f1_score(y_fold_val, fold_pred, average='weighted')\n",
    "        cv_scores.append(fold_score)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('train_dataset.csv')\n",
    "test_data = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "print(\"\\nPreparing features...\")\n",
    "X_train_full = prepare_data(train_data)\n",
    "X_test = prepare_data(test_data)\n",
    "\n",
    "# Remove non-feature columns\n",
    "cols_to_drop = ['customer_experience', 'user_id', 'transaction_id', \n",
    "                'order_id', 'tracking_number']\n",
    "feature_cols = [col for col in X_train_full.columns if col not in cols_to_drop]\n",
    "\n",
    "X = X_train_full[feature_cols]\n",
    "y = train_data['customer_experience']\n",
    "\n",
    "# Feature selection using Random Forest\n",
    "rf_selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "selector = SelectFromModel(rf_selector, prefit=False)\n",
    "selector.fit(X, y)\n",
    "selected_features = X.columns[selector.get_support()].tolist()\n",
    "X = X[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "# Robust scaling\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = RobustScaler()\n",
    "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "# Target encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Hyperparameter optimization\n",
    "print(\"\\nOptimizing hyperparameters with Optuna...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': 'hist'\n",
    "})\n",
    "\n",
    "print(\"\\nBest parameters:\", best_params)\n",
    "\n",
    "# Train final model with best parameters\n",
    "print(\"\\nTraining final model...\")\n",
    "final_model = xgb.XGBClassifier(**best_params)\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = final_model.predict(X_val)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
    "\n",
    "weighted_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score: {weighted_f1:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': final_model.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False).head(10))\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"\\nMaking predictions on test set...\")\n",
    "test_predictions = final_model.predict(X_test)\n",
    "test_predictions_labels = le.inverse_transform(test_predictions)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': range(len(test_predictions_labels)),\n",
    "    'customer_experience': test_predictions_labels\n",
    "})\n",
    "submission.to_csv('submission11.csv', index=False)\n",
    "print(\"\\nSubmission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c38c3-664e-466d-bef8-993cd24ce258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
